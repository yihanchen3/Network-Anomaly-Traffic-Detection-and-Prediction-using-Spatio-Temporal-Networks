{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "e4UIGRRZpBwJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Reshape,Conv2D,Flatten,MaxPooling1D,Conv1D,LSTM,Bidirectional,GRU,Dropout\n",
        "from attention import Attention\n",
        "from tcn import TCN, tcn_full_summary\n",
        "from tensorflow import compat,config\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from math import floor\n",
        "import prettytable as pt\n",
        "from contextlib import redirect_stdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# random seed set\n",
        "SEED = 1\n",
        "from numpy.random import seed \n",
        "seed(SEED) \n",
        "\n",
        "#function to convert dataframe to into 2d array\n",
        "def convert_2d(df_dup):\n",
        "    data_frame = pd.DataFrame()\n",
        "    for i in range(0, df_dup.shape[0]-59):\n",
        "        is_anomaly = False\n",
        "        mylist = []\n",
        "        for j in range(i, i+60):\n",
        "            mylist.append(df_dup['value'].iat[j])\n",
        "            if df_dup['is_anomaly'].iat[j] == 1:\n",
        "                is_anomaly = True\n",
        "        if is_anomaly:\n",
        "            mylist.append(1)\n",
        "        else:\n",
        "            mylist.append(0)\n",
        "        np_Array = np.array(mylist)\n",
        "        mylist = np_Array.T\n",
        "        data_frame = data_frame.append(pd.Series(mylist), ignore_index=True)\n",
        "    return data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# display dataset example \n",
        "df=pd.read_csv(\"Dataset/real_1.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(df.timestamp,df.value)\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.ylabel(\"NormalizedValue\")\n",
        "plt.title(\" Example plot of web traffic after preprocessing \")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing the data\n",
        "# dataset build\n",
        "args_data = 1 # 方法1读取已经预处理好的数据，快；方法2读取原始数据进行预处理，慢\n",
        "\n",
        "if args_data == 1:\n",
        "    frame = pd.read_excel('dataframe.xlsx',engine='openpyxl')\n",
        "elif args_data == 2:\n",
        "    path = r'Dataset' #set the path accordingly\n",
        "    all_files=glob.glob(path+\"/*.csv\")\n",
        "    dataset_conc=[]\n",
        "    for filename in tqdm(all_files):\n",
        "        df=pd.read_csv(filename,index_col=None,header=0)\n",
        "        df=df.replace(0,np.nan)\n",
        "        df=df.dropna(axis=0, how='any',subset=['value'])\n",
        "        df.value = preprocessing.normalize([df.value]).T\n",
        "        dataset_conc.append(convert_2d(df)) \n",
        "    frame=pd.concat(dataset_conc,axis=0,ignore_index=True)\n",
        "    #将dataframe写入excel方便查看\n",
        "    if os.path.exists('dataframe.xlsx'):\n",
        "        pass\n",
        "    else:\n",
        "        with pd.ExcelWriter('dataframe.xlsx') as writer:\n",
        "            frame.to_excel(writer, sheet_name='Sheet1',startcol=0,index=False)\n",
        "frame.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#split train & test dataset \n",
        "y=frame.iloc[:, 60]\n",
        "X=frame.iloc[:, 0:60]\n",
        "X_train = X[:int(X.shape[0]*0.7)]\n",
        "X_test = X[int(X.shape[0]*0.7):]\n",
        "y_train = y[:int(X.shape[0]*0.7)]\n",
        "y_test = y[int(X.shape[0]*0.7):]\n",
        "\n",
        "#reshaping the data \n",
        "X_train=X_train.to_numpy()\n",
        "nrows, ncols = X_train.shape\n",
        "X_train = X_train.reshape(nrows, ncols, 1)\n",
        "\n",
        "X_test=X_test.to_numpy()\n",
        "nrows, ncols = X_test.shape\n",
        "X_test = X_test.reshape(nrows, ncols, 1)\n",
        "\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "#converting y_train to categorical\n",
        "y_train = to_categorical(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "colab_type": "code",
        "id": "muJARzWyaSq1",
        "outputId": "22265acd-3563-476f-87c5-035572e8eec7"
      },
      "outputs": [],
      "source": [
        "# %%writefile model.txt  #取消注释本行代码可以将该代码块内容写至txt，但是不会执行代码块内容\n",
        "\n",
        "# define model structure\n",
        "model=Sequential()\n",
        "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu',input_shape=(60, 1),kernel_initializer='he_normal'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=2))\n",
        "model.add(Reshape((1,15*64)))\n",
        "model.add(TCN(64, activation='tanh',return_sequences='True'))\n",
        "model.add(Attention(units=32))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='tanh'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fi4zE8CKYyoL"
      },
      "outputs": [],
      "source": [
        "config.run_functions_eagerly(True)\n",
        "\n",
        "t_start = time.time()\n",
        "Time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(int(t_start)))\n",
        "sTime = time.strftime(\"%m%d//%H%M_\", time.localtime(int(t_start)))\n",
        "\n",
        "# train parameter set\n",
        "model_name = \"CNN+TCN+A+D\"\n",
        "batch_size = 512\n",
        "epoch = 500\n",
        "activation = 'relu'\n",
        "\n",
        "\n",
        "# 生成保存训练中间文件的文件夹\n",
        "path = 'train/' + sTime + model_name\n",
        "isExists=os.path.exists(path)\n",
        "if not isExists:\n",
        "    os.makedirs(path)\n",
        "print('folder made')\n",
        "\n",
        "print(model_name,'batch_size:',batch_size,'epochs:',epoch,'start time:',Time,'seed:',1)\n",
        "sess = compat.v1.Session(config=compat.v1.ConfigProto(log_device_placement=True))\n",
        "history=model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epoch, verbose=1)\n",
        "print('traing finished')\n",
        "\n",
        "t_end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save trained model\n",
        "model_file = path + '/trained_model.h5'\n",
        "model.save(model_file)\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# plot accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.savefig(path+'/accuracy.jpg')\n",
        "plt.show()\n",
        "\n",
        "# plot loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.savefig(path+'/loss.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "21lbZghj02U7"
      },
      "outputs": [],
      "source": [
        " #predicting on test data\n",
        "predict_x=model.predict(X_test) \n",
        "y_pred=np.argmax(predict_x,axis=1)\n",
        "\n",
        "#evaluate performance\n",
        "Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "Accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='binary')\n",
        "recall = recall_score(y_test, y_pred, average='binary')\n",
        "F1_Score = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "\n",
        "minute = floor((t_end-t_start)/60)\n",
        "second = ((t_end-t_start)/60-minute)*60\n",
        "if minute > 60:\n",
        "    hour = floor(minute/60)\n",
        "    minute = minute - 60*hour\n",
        "    train_t = '%dh%dm%ds'%(hour,minute,second)\n",
        "else:\n",
        "    train_t = '%dm%ds'%(minute,second)\n",
        "\n",
        "print(\"training time \",train_t)\n",
        "print(\"Confusion_Matrix\")\n",
        "print(Confusion_Matrix)\n",
        "print(\"Accuracy \", Accuracy)\n",
        "print(\"Precision \", precision)\n",
        "print(\"recall \", recall)\n",
        "print(\"f1_score \", F1_Score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save result to txt\n",
        "tb = pt.PrettyTable()\n",
        "tb.field_names = [\"Training Time\", \"Accuracy\", \"Precision\", \"Recall\",\"F1 Score\"]\n",
        "tb.add_row([train_t,Accuracy,precision,recall,F1_Score])\n",
        "tb1 = pt.PrettyTable()\n",
        "tb1.field_names = [\"Structure\",\"batch_size\", \"epochs\", \"start time\", \"seed\",\"activation\"]\n",
        "tb1.add_row([model_name,batch_size,epoch,Time,0,activation])\n",
        "print(tb)\n",
        "with open(path + '/result.txt','w+') as f:\n",
        "    f.write(str(tb))\n",
        "    f.write('\\n')\n",
        "    f.write(str(tb1))\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()\n",
        "    f.write('\\n')\n",
        "    # with open(\"model.txt\", \"r\") as file: # 记录模型定义代码块\n",
        "    #     data = file.read()  \n",
        "    #     f.write(data)\n",
        "print('tb finish')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CLSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "eacad346e278f4eb4f0c4be754826f9134eae7a25fcbb764db3d90651ebffe61"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
